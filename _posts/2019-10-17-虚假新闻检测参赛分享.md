---
layout:     post
title:      分享-智源-虚假新闻识别参赛历程
subtitle:   文本二分类问题
date:       2019-10-17
author:     iceberg
header-img: img/post-bg-coffee.jpeg
catalog: true
tags:    
        - NLP
        - 竞赛
        - 文本分类
---

# 一、关于智源-虚假新闻识别竞赛：

参考：[智源比赛链接](https://www.biendata.com/competition/falsenews/)

## 1、背景

虚假新闻识别问题出现时间蛮久了，收集了已有的做法，主要基于新闻的内容和报导的口吻这两个方面进行识别，以下是一些方法：

1）基于新闻内容：

真实新闻着眼于报道的主要观点，描述客观事实，观点客观中肯，少有夸张成分、诱导成分；

分析新闻的类别，挖掘分析哪类新闻出现虚假的可行性大一些（该方法还需要先对新闻做类别划分，难度不大，但是个人认为太复杂，且类别只能做参考，没有太大的必要做这个类别划分）

2）基于报导口吻及其他：

新闻的可读性，认为真实的新闻比假新闻的可读性要好，文字、语句更加平整，引述的专业词汇也较多，表述更加稳定；而假新闻的篇幅通常较短，引述的专业词汇较少，副词较多等；

分析虚假新闻的文本表述方式，假新闻在写作手法上有共通之处，通过计算相似度判断是否为虚假新闻；

类似的，新闻根据作者划分群体，相当于群体投票的方式，权威作者群体的创作相对更加可信；

真实和虚假新闻的传播方式不同，真实新闻的传播主要是靠用户从单个可靠消息源的直接分享，而假新闻的传播则主要依托用户间的分享；

...等等还有其他一些研究

## 2、思考

数据层面：该比赛数据只有文本以及对应的真假标识（0真实/1虚假），没有外部链接和外部辅助数据，不能使用作者、权威程度、网站的规范程度、真实事件对比及社交网络等进行辅助识别。

第一个考虑是从文本语义以及句法风格上考虑，检测新闻的客观程度（情感倾向，一般新闻的原则是描述客观事实），表述是否夸张，表述的目的性等，以及挖掘真实和虚假新闻的特征，例如文本长度、关键词、特殊符号等，然后使用传统机器学习的方法进行分类，例如朴素贝叶斯、逻辑回归等。

第二个考虑是用深度学习的方法，通过观察数据发现，真实样本和虚假样本特征重合较多，样本较为分散，语义层面的特征较难提取。

## 3、方法和结果

在建模之前首先对文本进行预处理，提取通用字段，使文本更加平整，减少噪音，这是保证模型的基本。

1）fasttext方法：

Facebook开源的文本分类方法，速度很快，ngram=2，第一次F1:82.3%, 简单调参后F1:82.9%

fasttext没有用到词序语义关系，拟合的是char、ngram_char跟label的概率指向P(X|Y)

后续可以做两个改进，一是完善文本预处理，用的是我工作中持续完善的预处理方法，这个方法提升不会很大了；二是外加词典，手工提取一些特征，用于修正输出结果，这个结果不能保证结果是否往好的方向走，本人提了一版词典，效果反而下降了，没往下再做了

2）bilstm+attention：

常规方法，训练集上acc:95%+，测试集F1:78%，效果不好，过拟合严重，稍微调了调参数（主要是学习率、batch_size等），达到80%

训练集上过拟合严重，对测试集的表现可以说很一般了，还不如fasttext。

另外，第一版用的nn.BCELoss作为损失函数，由于限定0-1输出，因此最后一层加了Sigmoid函数，结果出现梯度爆炸，模型输出集中在0.5，这是最差的结果，小伙伴们用sigmoid的时候要注意呀，可以使用relu、tanh来做激活，替换sigmoid，换了之后如果还使用交叉熵作为损失函数，可以用nn.CrossEntropyLoss，需要注意的是这个函数最后自动接一层softmax，对比的label必须为标量，且索引要从0开始。

看过其他人的项目，该方法

3）bert：

谷歌的预训练模型，最后一层输出为768维的词向量，后接一层LR, 训练集acc:0.99, 测试集F1：0.8569
非常惊讶，效果没有很大的提升！！！

本来想再试试bert+CNN,bert+transformer，奈何提交的时候发现验证已结束，尴尬，也不清楚这几个方法的效果如何了，anyway，这次以学习为主，后续换个数据集再对比一下各种方法的效果

## 4、总结

本次比赛以学习为主，平时工作较忙，在比赛上花的时间不多，个人最好成绩85.69%，排名不算靠前，后续继续努力，加油~







