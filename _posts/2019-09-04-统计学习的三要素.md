---
layout:     post
title:      统计学习三要素
subtitle:   从0-1了解统计学习
date:       2019-09-04
author:     qism
header-img: img/post-bg-coffee.jpeg
catalog: true
tags:    
        - 统计学习方法
        - 算法
---

# 一、统计学习的三要素：

1、模型，某条件概率分布或决策函数；假设空间包含了所有可能的条件概率分布或决策函数。假设空间是所有可能将X映射为y的函数集合，映射通过参数空间实现

2、策略，已知假设空间，如何寻找最优的条件概率分布或决策函数，常用方法是定义损失函数L(x,y)，则L(x,y)的期望就是模型平均意义下的损失，选择期望损失最小的模型。这里存在一个问题，即期望损失的计算需要知道联合概率分布，而这个分布其实是不知道的，因此无法直接计算期望损失。因此，常用的方法是通过参数估计的方法来估计期望损失。经验风险用于估计平均损失。当训练集数据较小的时候。模型容易过拟合，可以加入一个正则项来做修正，这个正则项是模型复杂度的函数，复杂度越高，这个值越大，损失函数就越大。因此，此时的策略就是寻找结构风险最小的模型。正则项通常是参数向量的范数（L1、L2等）

3、算法：指求解最优模型的方法，具体计算方法，比如梯度下降，前向后向算法等

这句话的理解

![正则化的贝叶斯解释](/img/post-20190904-pic-01.jpg ''奥卡姆剃刀原理'')

先验概率，有因推果，累计为特征推分类，假设模型很复杂，特征很多，则由已知分类推某特征出现的概率会越小

# 二、模型的泛化能力

两个因素：样本容量和假设空间容量，通俗点讲就是训练样本(N)越多，可选的模型(d)越小，范化误差的上界就越小
泛化误差<=训练误差+f(N,d)

# 三、生成模型和判别模型

生成模型，学习x和Y的联合概率分布，并预测条件概率p(y|x),模型收敛较快，还能解决隐变量的问题。常见的有朴素贝叶斯、隐马尔科夫随机场

判别模型：直接学习p(y|x)，不能还原联合概率分布，学习准确率高，简化了问题，更加直接。常见的有感知机、K近邻、决策树、逻辑回归、最大熵、SVM、CRF等。

# 四、指标区别

TP-将正类预测为正类数

FN-将正类预测为负类数

FP-将负类预测为正类数

TN-将负类预测为负类数

准确率：某个类预测准确占比，基数肯定是预测结果中所有正类的数量

```math
    P = \tfrac{TP}{TP + FP}
```

召回率：查全率，在所有的正类中，预测准确为正类的占比，基数是所有正类的数量

```math
    R = \tfrac{TP}{TP + FN}
```

F1:准确率和召回率有此消彼长的问题，综合两个指标

```math
    \tfrac{2}{F_1} = \tfrac{1}{P} + \tfrac{1}{R} 
```

```math
    F_1 = \tfrac{2TP}{2TP +FP +FN} 
```

# 五、三类问题

分类问题：监督学习的主要问题，主要有二分类和多分类，接下来会讲到很多不同的分类器

标注问题：比较简单，了解隐马尔科夫随机场和CRF的可以跳过。常用维特比解码，应用广泛，比如自然语言处理中的词性标注

回归问题：按照变量个数划分：一元和多元回归；按照模型类型划分：线性和非线性回归。常用算法，最小二乘法
